# DSA202515_Project
Repositorio del proyecto del trabajo final para la materia de Despliegues de Soluciones  Anal√≠ticas. 

*Grupo 28*
Integrado por:
- *Tatiana Cardenas*
- *Verny Mendoza*
- *David Castiblanco*
- *Holman Zarta*

#### *Nota: Este es el repositorio desarrollado por el equipo, enfocado en la clasificacion √∫nica de ocupaciones en Colombia.*

# Manual 1 ‚Äì Modelo CUOC (Entrenamiento y Serializaci√≥n)

# Clasificador de C√≥digos CUOC para Ofertas de Empleo  
Herramienta de recomendaci√≥n de c√≥digos CUOC a partir de descripciones textuales

Proyecto MLOps ‚Äì Grupo 28

---

## üìã Descripci√≥n

Este repositorio contiene el flujo de datos y el modelo de Machine Learning para **recomendar c√≥digos CUOC** (Clasificaci√≥n √önica de Ocupaciones para Colombia) a partir del **texto de la oferta de empleo**.

Dado el texto de una oferta laboral, el modelo sugiere los c√≥digos CUOC m√°s probables asociados a ese perfil.

---

## üéØ Objetivo

Predecir autom√°ticamente el **c√≥digo CUOC m√°s probable** (y candidatos alternativos) a partir de:

- La descripci√≥n de la oferta de empleo (`Descripcion_oferta`).
- El c√≥digo CUOC asignado hist√≥ricamente (`CUOC`), usado como etiqueta de entrenamiento.

La herramienta devuelve:

- Un conjunto de **c√≥digos CUOC recomendados**.
- Un **top 5** de c√≥digos con sus probabilidades estimadas.

---

## üèóÔ∏è Arquitectura del proyecto

Estructura principal del repositorio:

```text
.
‚îú‚îÄ‚îÄ assets/                              # Logos usados en el dashboard
‚îÇ   ‚îú‚îÄ‚îÄ logo_uniandes.png
‚îÇ   ‚îî‚îÄ‚îÄ logo_spe.png
‚îú‚îÄ‚îÄ Ofertas_proyecto_U_DSA202515.parquet.dvc   # Dataset de ofertas versionado con DVC
‚îú‚îÄ‚îÄ PerfilesOcupacionales-Excel-CUOC-2025.xlsx # Cat√°logo oficial CUOC
‚îú‚îÄ‚îÄ Proyecto_DSA_grupo28.ipynb           # Notebook de exploraci√≥n y entrenamiento
‚îú‚îÄ‚îÄ app_final.py                         # Aplicaci√≥n web Dash (modelo embebido)
‚îú‚îÄ‚îÄ modelo_cuoc_rf_compacto.pkl          # Modelo entrenado y compactado (RandomForest)
‚îú‚îÄ‚îÄ requirements.txt                     # Dependencias del proyecto
‚îú‚îÄ‚îÄ Procfile                             # Start command para Railway
‚îî‚îÄ‚îÄ README.md                            # Documentaci√≥n general del proyecto
```
- La estructura puede incluir archivos adicionales (.dvc, im√°genes, etc.), pero los anteriores son los componentes centrales del modelo y su despliegue.

---

## üìä Datasets utilizados

### 1. Ofertas laborales hist√≥ricas

**Archivo:** `Ofertas_proyecto_U_DSA202515.parquet`  
(seguido mediante `Ofertas_proyecto_U_DSA202515.parquet.dvc`)

Variables principales:

- `Descripcion_oferta`: texto completo de la oferta de empleo.  
- `CUOC`: c√≥digo CUOC etiquetado para esa oferta.  
- Otras variables (ciudad, nivel educativo, etc.), usadas principalmente para an√°lisis exploratorio.

Este dataset es la base para entrenar el clasificador CUOC.

### 2. Cat√°logo CUOC oficial

**Archivo:** `PerfilesOcupacionales-Excel-CUOC-2025.xlsx`

Variables principales:

- `CUOC`: c√≥digo de ocupaci√≥n.  
- `Descripci√≥n`: nombre de la ocupaci√≥n.  
- Informaci√≥n adicional sobre funciones y perfiles ocupacionales.

En el modelo se usa principalmente para:

- Construir un diccionario de c√≥digos ‚Üí descripciones.  
- Enriquecer la presentaci√≥n de resultados en el dashboard.

---

## üîß Preprocesamiento y balanceo

### Limpieza y normalizaci√≥n de texto

- Conversi√≥n a min√∫sculas.  
- Tokenizaci√≥n simple por espacios.  
- **Lematizaci√≥n** con NLTK (`WordNetLemmatizer`) para reducir palabras a su forma base (√©nfasis en verbos).

Funci√≥n utilizada (a nivel conceptual):

- Recibe el texto.
- Lo pasa a min√∫sculas.
- Separa en palabras por espacios.
- Aplica lematizaci√≥n verbo a verbo.

Esta funci√≥n se pasa como `analyzer` al `CountVectorizer`, de modo que el mismo preprocesamiento se aplique tanto en entrenamiento como en predicci√≥n.

### Balanceo de clases: `adaptive_resample`

El problema original presenta fuerte desbalance entre c√≥digos CUOC (muchas clases con pocos registros).  
Se define una funci√≥n de remuestreo que:

- Para clases con pocos registros: realiza **sobremuestreo con reemplazo** hasta un n√∫mero objetivo (`target_samples`).  
- Para clases muy frecuentes: realiza **submuestreo suave**, limitando el tama√±o m√°ximo de registros por clase.

Resultado: un dataset de entrenamiento **m√°s balanceado**, que mejora la capacidad del modelo para sugerir c√≥digos menos frecuentes.

---

## ü§ñ Modelo entrenado

### Tipo de modelo

- **Vectorizaci√≥n:** `CountVectorizer` con `analyzer=split_into_lemmas`.  
- **Clasificador:** `RandomForestClassifier` multiclase.

Para hacer el modelo viable en entornos con memoria limitada (como Railway), se entren√≥ una **versi√≥n compacta**:

- `max_features` en `CountVectorizer` reducido (vocabulario limitado).  
- √Årboles con profundidad acotada (`max_depth`).  
- N√∫mero de √°rboles moderado (`n_estimators`).  
- L√≠mite en el tama√±o del conjunto de entrenamiento.

Ejemplo de pipeline (esquem√°tico):

- Etapa 1: `CountVectorizer` con lemas, m√°ximo ~3000 t√©rminos y `min_df` para filtrar t√©rminos muy raros.  
- Etapa 2: `RandomForestClassifier` con alrededor de 40 √°rboles, profundidad m√°xima 15, `max_features="sqrt"` y `min_samples_leaf=5`.

### Entrenamiento y evaluaci√≥n

Flujo general:

1. Carga del dataset de ofertas.  
2. Aplicaci√≥n de `adaptive_resample` para balancear clases.  
3. Separaci√≥n en conjunto de entrenamiento y prueba (`train_test_split`).  
4. Entrenamiento del pipeline `pipe_cuoc_rf`.  
5. Evaluaci√≥n con m√©tricas de clasificaci√≥n (accuracy y an√°lisis por clase).

M√©trica global (aprox.):

- **Accuracy:** ~0.39  

Dado que es un problema multiclase con muchas clases y fuerte desbalance, la m√©trica se interpreta como una **l√≠nea base razonable** para demostrar el flujo completo de MLOps y despliegue.

### Serializaci√≥n del modelo

Una vez entrenado, el modelo se guarda como archivo `.pkl`:

- Se utiliza `joblib.dump` para serializar el pipeline completo.
- El archivo resultante es `modelo_cuoc_rf_compacto.pkl`, que contiene:
  - El vectorizador entrenado.  
  - El clasificador Random Forest entrenado.  

Este archivo es el que se carga dentro de la aplicaci√≥n Dash para inferencia en producci√≥n.

---

## üöÄ Instalaci√≥n y uso local

### 1. Clonar el repositorio

    git clone https://github.com/vernymendoza/DSA202515_Project.git
    cd DSA202515_Project

### 2. Crear entorno virtual e instalar dependencias

    python -m venv .venv

Activar entorno:

- Windows:  
  `.venv\Scripts\activate`
- Linux/Mac:  
  `source .venv/bin/activate`

Instalar dependencias:

    pip install --upgrade pip
    pip install -r requirements.txt

### 3. (Opcional) Recuperar datos con DVC

Si se tiene configurado el remoto DVC:

    dvc pull

Esto descarga el dataset de ofertas y otros artefactos versionados.

### 4. Reentrenar el modelo (opcional)

Abrir el notebook:

    jupyter notebook Proyecto_DSA_grupo28.ipynb

Seguir las secciones de:

- Carga de datos.  
- Preprocesamiento y balanceo.  
- Entrenamiento.  
- Evaluaci√≥n.  
- Exportaci√≥n del modelo como `modelo_cuoc_rf_compacto.pkl`.

Si no se desea reentrenar, se puede utilizar directamente el `.pkl` incluido en el repositorio.

---

## üß© Artefactos generados

- `modelo_cuoc_rf_compacto.pkl`  
  Modelo de clasificaci√≥n CUOC listo para uso en producci√≥n (consumido por la app Dash).

- `Proyecto_DSA_grupo28.ipynb`  
  Notebook con:
  - An√°lisis exploratorio.  
  - Preprocesamiento y balanceo.  
  - Entrenamiento y evaluaci√≥n.  
  - Generaci√≥n del modelo serializado.

- Archivos `.dvc`  
  Referencias a los datasets gestionados con DVC.

---

## üö® Troubleshooting

- **Error al cargar el modelo (`FileNotFoundError`)**  
  Verificar que `modelo_cuoc_rf_compacto.pkl` exista en la ra√≠z del proyecto y que el c√≥digo apunte a ese nombre (`MODELO_PATH = "modelo_cuoc_rf_compacto.pkl"`).

- **Incompatibilidades de `scikit-learn`**  
  Asegurar que la versi√≥n instalada sea compatible con el modelo entrenado.  
  Se recomienda instalar siempre desde `requirements.txt`.

- **Problemas de memoria al reentrenar**  
  Reducir:
  - `max_features` del `CountVectorizer`.  
  - `n_estimators` y `max_depth` del `RandomForestClassifier`.  
  - Tama√±o de la muestra de entrenamiento.

---

## üë• Equipo ‚Äì Grupo 28

- *Tatiana Cardenas*
- *Verny Mendoza*
- *David Castiblanco*
- *Holman Zarta*

Este proyecto hace parte del curso **Despliegue de Soluciones Anal√≠ticas (MLOps) ‚Äì MIAD, Universidad de los Andes**.






